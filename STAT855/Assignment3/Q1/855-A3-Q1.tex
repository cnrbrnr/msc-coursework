\documentclass[11pt, letterpaper]{article}
\usepackage[margin=1.5cm]{geometry}
\pagestyle{plain}

\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm}
\usepackage[shortlabels]{enumitem}
\usepackage[makeroom]{cancel}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{array, booktabs, ragged2e}
\graphicspath{{./Images/}}

\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\title{\bf Stochastic Processes: Assignment III}
\author{\bf Connor Braun}
\date{}

\begin{document} 
    \maketitle
    \noindent{\bf Problem 1} Let $\mc{S}$ and $\mc{U}$ be finite sets, referred to as the state and action space respectively.
    For each action $u\in\mc{U}$, it is associated with a transition matrix $P^{(u)}=\{P_{i,j}^{(u)}:i,j\in\mc{S}\}$. A policy is a mapping
    $\mu:\mc{S}\rightarrow\mc{U}$ from the state to the action space.\\[10pt]
    Fix a policy $\mu(\cdot)$. Consider the stochastic process ${(X_n,U_n):n\geq 0}$ with $X_n\in\mc{S}$ and $U_n\in\mc{U}$ for all $n\geq 0$.
    Specifically, for $n\geq 0$
    \[U_n=\mu(X_n)\]
    and moreover, for $n\geq 1$ and $i_0,i_1,\dots,i_{n+1}\in\mc{S}$,
    \[P(X_{n+1}=i_{n+1}|X_n=i_n,\dots,X_0=i_0)=P^{(u)}_{i_n,i_{n+1}},\quad\text{with $u=\mu(i_n)$}.\tag{1}\]
    Next, let $c:\mc{S}\times\mc{U}\rightarrow\mbb{R}$ be a cost function, and define the $\gamma$-discounted cost function as
    \[J^\mu(i)=\mbb{E}\left[\sum_{n=0}^\infty\gamma^nc(X_n,U_n)\bigg|X_0=i\right]\quad\text{for $i\in\mc{S}$}\tag{2}\]
    where in particular we require $\gamma\in(0,1)$. We view $J^\mu=(J^\mu(i):i\in\mc{S})$ as a column vector of length $|\mc{S}|$.\\[10pt]
    {\bf a)} Find a $|\mc{S}|\times 1$ vector $C$ and a $|\mc{S}|\times|\mc{S}|$ matrix $P^\mu$ so that
    \[J^\mu=C+\gamma P^\mu J^\mu.\]
    {\bf Solution} We begin by manipulating the $\gamma$-discounted cost function in (2). Let $i\in \mc{S}$. Then
    \begin{align*}
        J^\mu(i)&=\mbb{E}\left[\sum_{n=0}^\infty\gamma^n c(X_n,U_n)\bigg|X_0=i\right]\\
        &=\mbb{E}\left[c(X_0,U_0)+\sum_{n=1}^\infty\gamma^n c(X_n,U_n)\bigg|X_0=i\right]\\
        &=\mbb{E}[c(X_0,U_0)|X_0=i]+\sum_{j\in \mc{S}}P_{i,j}^{(\mu(i))}\mbb{E}\left[\sum_{n=1}^\infty\gamma^n c(X_n,U_n)\bigg|X_0=i,X_1=j\right]\tag{3}
    \end{align*}
    Where we have used the law of total expectation in (3). However, property (1) indicates that this process is Markovian. That is, for $n\geq 1$ and $i_0,i_1,\dots,i_{n+1}\in\mc{S}$,
    \[P(X_{n+1}=i_{n+1}|X_n=i_n,\dots,X_0=i_0)=P^{(\mu(i_n))}_{i_n,i_{n+1}}=P(X_n=i_{n+1}|X_n=i_n)\]
    so we can continue to simplify (3) by writing
    \begin{align*}
        J^\mu(i)&=\mbb{E}[c(X_0,U_0)|X_0=i]+\sum_{j\in \mc{S}}P_{i,j}^{(\mu(i))}\mbb{E}\left[\sum_{n=1}^\infty\gamma^n c(X_n,U_n)\bigg|X_0=i,X_1=j\right]\\
        &=\mbb{E}[c(i,\mu(i))]+\gamma\sum_{j\in \mc{S}}P_{i,j}^{(\mu(i))}\mbb{E}\left[\sum_{n=1}^\infty\gamma^{n-1}c(X_n,U_n)\bigg|X_1=j\right]\\
        &=c(i,\mu(i))+\gamma\sum_{j\in \mc{S}}P_{i,j}^{(\mu(i))}\mbb{E}\left[\sum_{n=0}^\infty\gamma^{n}c(X_n,U_n)\bigg|X_0=j\right]\\
        &=c(i,\mu(i))+\gamma\sum_{j\in\mc{S}}P_{i,j}^{(\mu(i))}J^\mu(j).
    \end{align*}
    From this, for $i,j\in\mc{S}$ we define
    \[C(i)=c(i,\mu(i))\quad\text{and}\quad P^\mu(i,j)=P^{(\mu(i))}_{i,j}\]
    so as to view $C=\{C(i):i\in\mc{S}\}$ as a $|\mc{S}|\times 1$ vector and $P^\mu=\{P^\mu(i,j):i,j\in\mc{S}\}$ as a $|\mc{S}|\times|\mc{S}|$ matrix satisfying the relationship
    \[J^\mu=C+\gamma P^\mu J^\mu.\tag*{$\qed$}\]
    {\bf b)} Let $\mc{S}=\{1,2,3\}$ and $\mc{U}=\{1,2\}$. Further, let
    \[P^{(1)}=\begin{pmatrix}
        1/2 & 1/4 & 1/4\\
        1/4 & 1/2 & 1/4\\
        1/4 & 1/4 & 1/2
    \end{pmatrix}\quad\text{and}\quad P^{(2)}=\begin{pmatrix}
        1/3 & 1/3 & 1/3\\
        1/3 & 1/3 & 1/3\\
        1/3 & 1/3 & 1/3
    \end{pmatrix}\]
    and $c(s,u)=su$ for each pair $(s,u)\in\mc{S}\times\mc{U}$. Consider the following policy:
    \[\mu(1)=1,\quad\mu(2)=2,\quad\mu(3)=1.\]
    For $\gamma=0.8$, report $C$, $P^\mu$ and $J^\mu$.\\[10pt]
    {\bf Solution} Using the expression found in the first part we can solve for $J^\mu$. Let $\mbb{I}$ be the identity matrix. Then
    \[J^\mu=C+\gamma P^\mu J^\mu\quad\Rightarrow\quad J^\mu-\gamma P^\mu J^\mu=C\quad\Rightarrow\quad (\mbb{I}-\gamma P^\mu)J^\mu=C\quad\Rightarrow\quad J^\mu=(\mbb{I}-\gamma P^\mu)^{-1}C\] 
    where in the last step we have assumed that the matrix $(\mbb{I}-\gamma P^\mu)$ is invertible. Of course, when we determine $(\mbb{I}-\gamma P^\mu)$ for the system at hand we will have to verify this is indeed the case.
    Formulae for $C$ and $P^\mu$ are immediately available in the first part, so we simply compute them programmatically (see Appendix A.1 for the code).\\[10pt]
    The program returns
    \[P^\mu=\begin{pmatrix}
        1/2 & 1/4 & 1/4\\
        1/3 & 1/3 & 1/3\\
        1/4 & 1/4 & 1/2
    \end{pmatrix}\quad\text{and}\quad C=\begin{pmatrix}
        1\\
        4\\
        3
    \end{pmatrix}.\]
    where now, rounding to five decimal places,
    \[(\mbb{I}-\gamma P^\mu)=\begin{pmatrix}
        0.60000 & -0.20000 & -0.20000\\
        -0.26667 & 0.73333 & -0.26667\\
        -0.20000 & -0.20000 & 0.60000
    \end{pmatrix}\]
    which is nonsingular as determined numerically. Thus we can compute the $\gamma$-discounted cost function, rounding to five decimal places once more, as
    \[J^\mu=(\mbb{I}-\gamma P^\mu)^{-1}C=\begin{pmatrix}
        10.89286\\
        14.28571\\
        13.39286
    \end{pmatrix}\]
    and we are done.\\[10pt]
    {\bf A.1 Code used for problem 1b}
    \begin{verbatim}
        # Compute gamma-discounted cost function for given system and parameters
        S = c(1, 2, 3) # state space
        U = c(1, 2) # action space
        gamma = 0.8 # discounting parameter

        # Action-dependent state probability transition matrices
        P_1 = matrix(c(1/2, 1/4, 1/4, 1/4, 1/2, 1/4, 1/4, 1/4, 1/2), nrow=3)
        P_2 = matrix(rep(1/3, 9), nrow=3)

        # Function for computing P_mu elementwise using formula in (a)
        P_ij = function(P_1, P_2, u, i, j){
            if (u == 1){
                e = P_1[i, j]
            }
            else {
                e = P_2[i, j]
            }
            return(e)
        }

        # Policy for selecting actions under the given policy
        policy = function(s) {
            if (s == 1){
                e = 1
            }
            else if (s == 2) {
                e = 2
            }
            else {
                e = 1
            }
            return(e)
        }

        # Initialize solution constructs
        P_mu = matrix(rep(0, length(S)**2), nrow=3)
        C = rep(0, length(S))

        # Find P_mu
        for (i in S){
            for (j in S){
                u = policy(i)
                P_mu[i, j] = P_ij(P_1, P_2, u, i, j)
            }
        }

        # Find C
        for (i in seq_along(S)){
            C[i] = S[i] * policy(S[i])
        }

        # Compute (I - gamma*P_mu)^-1
        I = diag(length(S))
        ic_trans = (I - (gamma * P_mu))
        inv_ic_trans = solve(sol_transform)

        # Solve for the gamma-discounted cost function
        J_mu = inv_ic_trans %*% C

        # Report solution and constructs
        ic_trans
        P_mu
        C
        J_mu
    \end{verbatim}
\end{document}