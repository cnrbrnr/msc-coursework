\documentclass[11pt, letterpaper]{article}
\usepackage[margin=1.5cm]{geometry}
\pagestyle{plain}

\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm}
\usepackage[shortlabels]{enumitem}
\usepackage[makeroom]{cancel}
\usepackage{graphicx}
\usepackage{calrsfs}
\usepackage{xcolor}
\usepackage{array, booktabs, ragged2e}
\graphicspath{{./Images/}}

\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\title{\bf Stochastic Processes: Assignment V}
\author{\bf Connor Braun}
\date{}

\begin{document}
    \maketitle
    \noindent{\bf Problem 3} A particle does a continuous-time random walk on a triangle with vertices $\mc{I}=\{A,B,C\}$ with $Q$-matrix given by
    \[Q=\begin{pmatrix}
        -2 & 1 & 1\\
        4 & -4 & 0\\
        2 & 1 & -3
    \end{pmatrix}.\]
    Denote by $X_t$ the position of the particle at time $t\geq 0$.\\[10pt]
    {\bf a)} Compute $P_{A,A}(t)=P(X_t=A|X_0=A)$ for $t\geq 0$.\\[10pt]
    {\bf Solution} For this problem we appeal to the backward equation. Letting $P(t)=\{P_{i,j}(t)=P(X_t=j|X_0=i):i,j\in\mc{I}\}$ be the transition probability matrix at time $t\geq 0$, we have the matrix-valued initial value problem 
    \[P^\prime(t)=QP(t)\quad P(0)=\mbb{I}\]
    with $\mbb{I}$ the identity matrix in $\mbb{R}^3$. The unique solution is given by
    \[P(t)=e^{Qt}=\sum_{k=0}^\infty\frac{(tQ)^k}{k!}.\tag{2}\]
    Suppose that $Q$ is diagonalizable. That is, $\exists U\in \mc{M}_{3\times 3}(\mbb{R})$ (the space of $3\times 3$ real matrices) non-singular so that
    \[Q=UDU^{-1},\quad D=\text{diag}\,(\sigma(Q))\]
    and $\sigma(Q)=\{\lambda\in\mbb{C}:\det(\lambda\mbb{I}-Q)=0\}$ is the spectrum of $Q$. Then (2) can be written as
    \[P(t)=\sum_{k=0}^\infty\frac{t^k(UDU^{-1})^k}{k!}=U\left(\sum_{k=0}^\infty\frac{(tD)^k}{k!}\right)U^{-1}=Ue^{Dt}U^{-1}\]
    further, observing that $(tD)^k/k!$ is diagonal $\forall k\geq 0$, we let $d_i$ and $\lambda_i$ be the $i$th diagonal entries of $e^Dt$ and $D$ respectively for $i=1,2,3$. With this, we find that 
    \[d_i=\sum_{k=0}^\infty\frac{(tD)^k_{i,i}}{k!}=\sum_{k=0}^\infty\frac{(t\lambda_i)^k}{k!}=e^{\lambda_it}\]
    so that
    \[P(t)=Ue^{Dt}U^{-1}=U\begin{pmatrix}
        e^{\lambda_1t} & 0 & 0\\
        0 & e^{\lambda_2 t} & 0\\
        0 & 0 & e^{\lambda_3 t}
    \end{pmatrix}U^{-1}.\]
    Thus, our desired function can be expressed in terms of the spectrum and eigenvectors of $Q$. We proceed numerically, with the code used to find the spectrum and eigenvectors of $Q$ available in Appendix A.2.\\[10pt]
    Indeed, $Q$ is diagonalizable, since its eigenvalues are pairwise distinct, and $\sigma(Q)=\{0, -5, -4\}$. We also have, rounding to four points of precision,
    \[U=\begin{pmatrix}
        0.5774 & 0.2357 & 0.0000\\
        0.5774 & -0.9428 & -0.7071\\
        0.5774 &   0.2357 & 0.7071
    \end{pmatrix}\quad\text{and}\quad U^{-1}=\begin{pmatrix}
        1.0392 & 0.3464 & 0.3464\\
        1.6971 & -0.8485 & -0.8485\\
        -1.4142 & 0 & 1.4142
    \end{pmatrix}\]
    so that $U\text{diag}\,(\sigma(Q))U^{-1}=Q$. Of course, then the desired probability $P_{A,A}(t)$ is simply given by the first diagonal entry of $Ue^{Dt}U^{-1}$, so
    \begin{align*}
        P_{A,A}(t)=(Ue^{Dt}U^{-1})_{1,1}&=(1.0392)(0.5774)e^{0t}+(1.6971)(0.2357)e^{-5t}+(-1.4142)(0)e^{-4t}\\
        &=0.6000+0.4000e^{-5t}.\tag*{$\qed$}
    \end{align*}
    {\bf b)} Implement the na\"ive Monte Carlo method to estimte 
    \[(P(X_t=A|X_0=A), P(X_t=B|X_0=A), P(X_t=C|X_0=A))\]
    for $t\in\{0.3, 5\}$.\\[10pt]
    {\bf Solution} See Appendix A.3 for the code used to do this. First, setting $t=0.3$, we simulate the continuous time Markov chain
    generated by $Q$ (which is non-explosive, since the state space is finite) $10^4$ times, noting $X_t$. We estimate $P_{A,Y}(t)$ as the proportion
    of realizations with $X_t=Y$, for $Y\in\mc{I}$.
    \[(P(X_t=A|X_0=A), P(X_t=B|X_0=A), P(X_t=C|X_0=A))=(0.6913, 0.1543, 0.1544)\]
    rounding to four decimal places. Now, setting $t=5$ and using the same technique, we estimate
    \[(P(X_t=A|X_0=A), P(X_t=B|X_0=A), P(X_t=C|X_0=A))=(0.6038, 0.1966, 0.1996)\]
    again rounded to four decimal places.\hfill{$\qed$}\\[10pt]
    \noindent{\bf\Large Appendix}\\[10pt]
    {\bf A.2 Code used for problem 3a}
    \begin{verbatim}
        # Define Q matrix
        Q = np.array(
            [
                -2, 1, 1,
                4, -4, 0,
                2, 1, -3
            ]
        ).reshape((3,3))

        spectrum, U = np.linalg.eig(Q) # obtain spectrum and eigenvectors
        U_inv = np.linalg.inv(U) # invert eigenvector matrix
        D = np.diag(spectrum) # create diagonal matrix of eigenvalues

        # Verify the diagonalization identity
        print(U @ D @ U_inv) # Evaluates to Q
    \end{verbatim}
    {\bf A.3 Code used for problem 3b}
    \begin{verbatim}
        def Q_to_Pi(Q):
            '''
            Generate jump chain transition kernel from Q matrix
                - Assumes all diagonal entries of Q nonzero
            '''

            Pi = Q / np.tile(np.abs(np.diagonal(Q)), 3).reshape((3,3)).T
            return Pi - np.diag(np.diagonal(Pi))

        def run_CTMC(Pi, Q, T, init_state):

            '''Contruct one CTMC realization from non-explosive Q matrix'''

            I = np.arange(Q.shape[0]) # create state space
            J_time = [0] # initialize jump times
            J_chain = [init_state] # initialize jump chain
            num_J = 0 # initialize jump counter

            # Create jumps until we exceed the simulation time allowance once
            while J_time[num_J] < T: 

                curr_time = J_time[num_J] 
                curr_state = J_chain[num_J]

                # Use current state to sample the corresponding holding time and state distributions
                hold = np.random.exponential(scale=(1 / np.abs(Q[curr_state, curr_state])))
                new_state = np.random.choice(I, p=Pi[curr_state, :])

                # Add latest state and jump time to data
                J_time.append(curr_time + hold)
                J_chain.append(new_state)

                # Increment number of jumps
                num_J += 1

            # Return data as column array of jump times and chain
            return np.concatenate(
                (np.array(J_time).reshape((-1, 1)), np.array(J_chain).reshape((-1, 1))),
                axis=1
            )


        # Define Q matrix
        Q = np.array(
            [
                -2, 1, 1,
                4, -4, 0,
                2, 1, -3
            ]
        ).reshape((3,3))
        Pi = Q_to_Pi(Q) # Generate jump chain transition kernel from Q

        # Simulation parameters
        num_runs = 1e4 # number of CTMC realizations to generate
        T = 5 # duration for each run
        init = 0 # initial state

        term_states = [] # initialize output 
        for run in range(int(num_runs)):

            data = run_CTMC(Pi, Q, T, init) # run CTMC

            # Extract state at time T
            term_row = np.where(data[:, 0] <= T)[0][-1]
            term_states.append(data[term_row, 1])

        term_states = np.array(term_states)

        # Estimate transition probabilities as proportions
        num_A = np.where(term_states == 0)[0].size
        num_B = np.where(term_states == 1)[0].size
        num_C = np.where(term_states == 2)[0].size

        transition_estimate = np.array([num_A, num_B, num_C]) / num_runs

        # Print result
        print(
            'Starting from {}, we transition to states [0,1,2] after {}s with probabilties {}'.format(
                init, T, transition_estimate
            )
        )
    \end{verbatim}
\end{document}
\end{document}