\documentclass[10pt]{article}
\usepackage[margin=1.3cm]{geometry}

% Packages
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm} 
\usepackage{dutchcal} % [dutchcal, calrsfs, pzzcal] calligraphic fonts
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[tracking]{microtype}

% Palatino for text goes well with Euler
\usepackage[sc,osf]{mathpazo}   % With old-style figures and real smallcaps.
\linespread{1.025}              % Palatino leads a little more leading

% Euler for math and numbers
\usepackage[euler-digits,small]{eulervm}

% Command initialization
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\graphicspath{{./images/}}

% Custom Commands
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\bp}[1]{\left({#1}\right)}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\1}[1]{\mathbbm{1}_{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\nck}[2]{{#1\choose#2}}
\newcommand{\pc}[1]{\pazocal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand*{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand*{\ceil}[1]{\left\lceil#1\right\rceil}

\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\as}{a.s.}
\DeclareMathOperator{\ale}{a.e.}
\DeclareMathOperator{\st}{s.t.}
\DeclareMathOperator{\io}{i.o.}
\DeclareMathOperator{\wip}{w.p.}
\DeclareMathOperator{\iid}{i.i.d.}
\DeclareMathOperator{\ifff}{if\;and\;only\;if}
\DeclareMathOperator{\inv}{inv}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}
    \begin{center}
        {\bf\large{MATH 895: CORE COURSE IN PROBABILITY}}
        \smallskip
        \hrule
        \smallskip
        {\bf Assignment} 2\hfill {\bf Connor Braun} \hfill {\bf 2024-02-17}
    \end{center}
    \noindent{\bf Problem 9}\\[5pt]
    Prove the following:\\[5pt]
    {\bf Theorem}\hspace{5pt} Let $X_1,\dots X_n$ be independent, real-valued random variables. Sppose that $0<\varepsilon,\delta<1$ are such that, for every $1\leq k\leq n$, we have
    $P\bp{\left|\sum_{j=k}^nX_j\right|\geq \frac{\varepsilon}{2}}\leq \delta$. Then
    \begin{align*}
        P\bp{\max_{1\leq k\leq n}\left|\sum_{j=1}^kX_j\right|\geq \varepsilon}\leq \frac{\delta}{1-\delta}.
    \end{align*}
    {\bf Proof}\hspace{5pt} We follow [1] in this proof. Let $(\Omega,\mc{F},P)$ be the common probability space on which $X_1,\dots, X_n$ are defined. As per the hint, we proceed in a manner similar to the proof of the Kolmogorov maximal inequality. That is, we partition our target event as
    \begin{align*}
        \mc{C}:=\bigsqcup_{k=1}^n\mc{C}_k\quad\text{with}\quad \mc{C}_k:=\left\{\omega\in\Omega:\left|\sum_{i=1}^jX_i\right|<\varepsilon\;\text{for $1\leq j<k$, and }\left|\sum_{i=1}^kX_i\right|\geq\varepsilon\right\}
    \end{align*}
    so $\mc{C}_k$ is the event that the $k$th partial sum $\sum_{j=1}^kX_k$ is the first to exceed $\varepsilon$ in absolute value. Observe that we have the inclusion
    \begin{align*}
        \left\{\omega\in\Omega:\left|\sum_{j=1}^{n}X_j-\sum_{j=1}^kX_j\right|<\frac{\varepsilon}{2},\quad\omega\in\mc{C}_k\right\}\subset\left\{\omega\in\Omega:\left|\sum_{j=1}^nX_j\right|\geq\frac{\varepsilon}{2},\quad\omega\in\mc{C}_k\right\}\tag{4}
    \end{align*}
    for $k\leq n$. For this, take $k\leq n$, and henceforth denote $S_k:=\sum_{j=1}^kX_j$ for $1\leq k\leq n$ as shorthand. If $\omega\in\Omega$ is such that $|S_n-S_k|<\tfrac{\varepsilon}{2}$ and $\omega\in\mc{C}_k$, then $|S_k|\geq\varepsilon$ and so $|S_n|\geq\tfrac{\varepsilon}{2}$. To see why, assume instead instead that $|S_n|<\tfrac{\varepsilon}{2}$, then we could produce the lower bound
    \begin{align*}
        \left|S_n-S_k\right|=\left|S_k-S_n\right|\geq ||S_k|-|S_n||\geq |S_k|-|S_n|>\varepsilon-\frac{\varepsilon}{2}=\frac{\varepsilon}{2}
    \end{align*}
    violating our assumption that $|S_n-S_k|<\tfrac{\varepsilon}{2}$. Equipped with (4), we compute
    \begin{align*}
        \delta\geq P\bp{\left|S_n\right|\geq\frac{\varepsilon}{2}}\geq P\bp{\left|S_n\right|\geq\frac{\varepsilon}{2},\;\max_{1\leq k\leq n}\left|S_k\right|\geq\varepsilon}&=P\bp{\left|S_n\right|\geq\frac{\varepsilon}{2},\;\bigsqcup_{k=1}^n\mc{C}_k}\\
        &=\sum_{k=1}^nP\bp{\left|S_n\right|\geq\frac{\varepsilon}{2},\; \mc{C}_k}\\
        &\geq \sum_{k=1}^nP\bp{|S_{n}-S_k|<\frac{\varepsilon}{2},\;\mc{C}_k}.\tag{by (4)}
    \end{align*}
    However, $\mc{C}_k$ depends only on $X_1,\dots,X_k$, and $\{|S_n-S_k|<\tfrac{\varepsilon}{2}\}$ only on $X_{k+1},\dots,X_n$ (or else is zero if $k=n$). Since $X_1,\dots,X_n$ are $\iid$, the probability in the last inequality factorizes, and we obtain
    \begin{align*}
        \delta\geq\sum_{k=1}^nP\bp{|S_{n}-S_k|<\frac{\varepsilon}{2},\;\mc{C}_k}&=\sum_{k=1}^nP\bp{|S_n-S_k|<\frac{\varepsilon}{2}}P\bp{\mc{C}_k}\\
        &=\sum_{k=1}^n(1-\delta)P(\mc{C}_k)\tag{since $P(|\sum_{j=k}^nX_j|\geq\tfrac{\varepsilon}{2})\leq\delta$}\\
        &=(1-\delta P\bp{\bigsqcup_{k=1}^n\mc{C}_k})\\
        &=(1-\delta)P\bp{\max_{1\leq k\leq n}\left|\sum_{j=1}^kX_j\right|\geq\varepsilon} 
    \end{align*}
    which implies the result
    \[P\bp{\max_{1\leq k\leq n}\left|\sum_{j=1}^kX_j\right|\geq \varepsilon}\leq \frac{\delta}{1-\delta}.\tag*{$\qed$}\]
    \vspace{10pt}
    \hrule
    \begin{center}
        {\bf\large Appendix}
    \end{center}
    {\bf A.1\hspace{5pt} Proofs of supplementary theorems}\\[5pt]
    {\bf Lemma} (Problem 7). Let $(\Omega,\mc{F},P)=(\Omega_1,\mc{F}_1,P_1)^{\mbb{N}}$ be the infinite product probability space on which a sequence of $\iid$ random variables $(X_k)_{k\geq 1}$ is defined. The set of
    exchangeable events
    \[\mc{E}=\{B\in\mc{F}:T_\sigma(B)=B\;\text{for all finite permutations $\sigma$}\}\]
    is a $\sigma$-field, where for a finite permutation $\sigma:\mbb{N}\rightarrow\mbb{N}$, $T_\sigma:\Omega\rightarrow\Omega$ is defined by
    $T_\sigma((\omega_i)_{i\geq 1})=(\omega_{\sigma(i)})_{i\geq 1}$.\\[5pt]
    {\bf Proof}\hspace{5pt} Let $\sigma$ be an arbitrary finite permutation, and note that $\sigma$ is a bijection. First, $\Omega\in\mc{E}$, since
    taking $\omega\in\Omega$, $\exists\omega^\prime\in\Omega:$ $T_\sigma(\omega^\prime)=\omega$ (surjectivity of $\sigma$) so $\Omega\subset T_\sigma(\Omega)$. But $T_\sigma(\omega)\in\Omega$ too, so we get $T_\sigma(\Omega)=\Omega$, and $\Omega\in\mc{E}$. Now, take $A\in\mc{E}$. Then
    \begin{align*}
        T_\sigma(\Omega\setminus A)=\Omega\setminus T_\sigma(A)=\Omega\setminus A
    \end{align*}
    so $\Omega\setminus A\in\mc{E}$, and $\mc{E}$ is closed under complementation. The first equality holds since if $\omega\in T_\sigma(\Omega\setminus A)$, then $\exists!\omega^\prime\in\Omega\setminus A:T_\sigma(\omega^\prime)=\omega$ (bijectivity of $\sigma$). From this, we get that $\forall \omega^{\prime\prime}\in A$, $T_\sigma(\omega^{\prime\prime})\neq\omega$, and thus $\omega\in\Omega\setminus T_\sigma(A)$.
    Conversely, if $\omega\in\Omega\setminus T_\sigma(A)$, then $\exists\omega^\prime\in\Omega:\omega= T_\sigma(\omega^\prime)$ (surjectivity of $\sigma$), but $\omega^\prime\notin A$ since $\omega\in\Omega\setminus T_\sigma(A)$, so $\omega\in T_\sigma(\Omega\setminus A)$.\\[5pt]
    Finally, let $(A_i)_{i\geq 1}\subset\mc{E}$ be a countable sequence of exchangeable events. Then
    \[T_\sigma\bp{\bigcup_{i=1}^\infty A_i}=\bigcup_{i=1}^\infty T_\sigma(A_i)=\bigcup_{i=1}^\infty A_i\]
    so $\cup_{i=1}^\infty A_i\in\mc{E}$, and $\mc{E}$ is closed under countable unions. Thus, $\mc{E}$ satisfies all $\sigma$-field axioms.\hfill{$\qed$}\\[5pt]
    \hrule
    \begin{center}
        {\bf\large References}
    \end{center}
    1. R.M. Dudley, {\it Real Analysis and Probability}, Cambridge University Press, Cambridge, 2002. \\[5pt]

\end{document}