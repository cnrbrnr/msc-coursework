\documentclass[10pt]{article}
\usepackage[margin=1.3cm]{geometry}

% Packages
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm} 
\usepackage{dutchcal} % [dutchcal, calrsfs, pzzcal] calligraphic fonts
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[tracking]{microtype}

% Palatino for text goes well with Euler
\usepackage[sc,osf]{mathpazo}   % With old-style figures and real smallcaps.
\linespread{1.025}              % Palatino leads a little more leading

% Euler for math and numbers
\usepackage[euler-digits,small]{eulervm}

% Command initialization
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\graphicspath{{./images/}}

% Custom Commands
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\bp}[1]{\left({#1}\right)}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\1}[1]{\mathbbm{1}_{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\nck}[2]{{#1\choose#2}}
\newcommand{\pc}[1]{\pazocal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand*{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand*{\ceil}[1]{\left\lceil#1\right\rceil}

\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\as}{a.s.}
\DeclareMathOperator{\ale}{a.e.}
\DeclareMathOperator{\st}{s.t.}
\DeclareMathOperator{\io}{i.o.}
\DeclareMathOperator{\wip}{w.p.}
\DeclareMathOperator{\iid}{i.i.d.}
\DeclareMathOperator{\ifff}{if\;and\;only\;if}
\DeclareMathOperator{\inv}{inv}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}
    \begin{center}
        {\bf\large{MATH 895: CORE COURSE IN PROBABILITY}}
        \smallskip
        \hrule
        \smallskip
        {\bf Assignment} 3\hfill {\bf Connor Braun} \hfill {\bf 2024-03-22}
    \end{center}
    \noindent{\bf Problem 10}\\[5pt]
    Let $(X_k)_{k\geq 1}$ be a sequence of $\iid$ uniform random variables on $\left[-\tfrac{1}{2},\tfrac{1}{2}\right]$. Consider the sequence of random variables $(S_n)_{n\geq 1}$, defined as
    $S_n=\tfrac{1}{n}\sum_{k=1}^n\tfrac{1}{X_k}$. Find the limit (in law) of $S_n$ as $n\rightarrow\infty$.\\[5pt]
    {\bf Solution}\hspace{5pt} Denote the characteristic functions of $S_n$, $1/X_n$ as $\varphi_{S_n}$, $\varphi_{X_n^{-1}}$ respectively. Then, using the previous result, we have
    \begin{align*}
        \varphi_{S_n}(t)=\E{\bp{e^{\tfrac{it}{n}\sum_{k=1}^n\tfrac{1}{X_k}}}}=\E{\bp{\prod_{k=1}^ne^{i\tfrac{t}{n}X_k^{-1}}}}=\prod_{k=1}^n\varphi_{X_k^{-1}}(t/n)=(\varphi_{X_1^{-1}}(t/n))^n
    \end{align*}
    with the last equality holding since the uniform random variables are $\iid$ Now, define $\varphi_{X_1^{-1}}^{+\prime}(t)$ and $\varphi_{X_1^{-1}}^{-\prime}$ to be the right- and left-sided derivatives of $\varphi_{X_1^{-1}}$ evaluated at $t\in\mbb{R}$, respectively. Specifically,
    \begin{align*}
        \varphi_{X_1^{-1}}^{+\prime}(0)=\lim_{h\rightarrow 0^+}\frac{\varphi_{X_1^{-1}}(h)-\varphi_{X_1^{-1}}(0)}{h}=\lim_{h\rightarrow 0^+}\frac{1}{h}\bp{\int_\mbb{R}e^{\tfrac{ih}{x}}dx-1}=\lim_{h\rightarrow 0^+}\frac{1}{h}\bp{\int_{-1/2}^{1/2}e^{\tfrac{ih}{x}}dx-1}
    \end{align*}
    and identically,
    \begin{align*}
        \varphi_{X_1^{-1}}^{-\prime}(0)=\lim_{h\rightarrow 0^-}\frac{1}{h}\bp{\int_{-1/2}^{1/2}e^{\tfrac{ih}{x}}dx-1}.
    \end{align*}
    In fact, we can simplify the integrands involved in both expressions somewhat:
    \begin{align*}
        \int_{-1/2}^{1/2}e^{\tfrac{ih}{x}}dx=\int_{-1/2}^{1/2}=\cos(h/x)+i\sin(h/x)dx=\int_{-1/2}^{1/2}\cos(h/x)dx
    \end{align*}
    but no further -- we turn to Wolfram Alpha to compute this integral, and obtain the result [4]:
    \begin{align*}
        \int_{-1/2}^{1/2}\cos(h/x)dx&=2h\int_0^{2h}\frac{\sin(t)}{t}dt+\cos(2h)-\pi|h|.
    \end{align*}
    Equipped with this expression, we may compute the one-sided derivatives of $\varphi_{X_1^{-1}}$ at $0$.
    \begin{align*}
        \varphi_{X_1^{-1}}^{+\prime}(0)=\lim_{h\rightarrow 0^+}\frac{1}{h}\bp{2h\int_0^{2h}\frac{\sin(t)}{t}dt+\cos(2h)-\pi|h|-1}&=\lim_{h\rightarrow 0^+}2\int_0^{2h}\frac{\sin(t)}{t}dt-\frac{\pi h}{h}+\lim_{h\rightarrow 0^+}\frac{\cos(2h)-1}{h}.
    \end{align*}
    This last term, irrespective of the side the limit is taken from, may be computed via L'H\^opital's rule:
    \begin{align*}
        \lim_{h\rightarrow 0}\frac{\cos(2h)-1}{h}=\lim_{h\rightarrow 0}\frac{-2\sin(2h)}{1}=0
    \end{align*}
    so that we may continue on to find
    \begin{align*}
        \varphi_{X_1^{-1}}^{+\prime}(0)=\lim_{h\rightarrow 0^+}2\int_0^{2h}\frac{\sin(t)}{t}dt-\pi=-\pi
    \end{align*}
    in precisely the same manner, we also obtain
    \begin{align*}
        \varphi_{X_1^{-1}}^{-\prime}(0)=\lim_{h\rightarrow 0^-}\frac{1}{h}\bp{2h\int_0^{2h}\frac{\sin(t)}{t}dt+\cos(2h)-\pi|h|-1}=\lim_{h\rightarrow 0^-}2\int_0^{2h}\frac{\sin(t)}{t}dt+\pi=\pi
    \end{align*}
    noting that the side from which we took the limit only alters the result through the $-\pi|h|$ term present in both expressions. This has shown us that the derivative of $\varphi_{X_1^{-1}}$ does not exist at zero,
    but we may restrict its domain to $\mbb{R}_{>0}$ or $\mbb{R}_{<0}$ separately and use one-sided derivatives to approximate the function. To see why, consider the following:
    \begin{align*}
        \varphi_{X_1^{-1}}^{+\prime}(0)=\lim_{h\rightarrow 0^+}\frac{\varphi_{X_1^{-1}}(h)-\varphi_{X_1^{-1}}(0)}{h}\quad\Rightarrow\quad\varphi_{X_1^{-1}}(h)=1+\varphi_{X_1^{-1}}^{+\prime}(0)h+o(h)\tag{8}
    \end{align*}
    which furnishes an approximation when $h>0$ which becomes exact when $h\rightarrow 0^+$. Thus, taking $t>0$, we have
    \begin{align*}
        \varphi_{S_n}(t)=(\varphi_{X_1^{-1}}(t/n))^n=\bp{1+\varphi_{X_1^{-1}}^{+\prime}(0)\frac{t}{n}+o(t/n)}^n=\bp{1+\frac{-\pi t+no(t/n)}{n}}^n\longrightarrow e^{-\pi t}\quad\text{as $n\rightarrow\infty$}\tag{9}
    \end{align*}
    where the $no(t/n)$ term has vanished in the limit as $n\rightarrow\infty$. An identical expression to (8) can be derived for the left-derivative:
    \begin{align*}
        \varphi_{X_1^{-1}}(h)=1+\varphi_{X_1^{-1}}^{-\prime}(0)h+o(h)
    \end{align*}
    holding when $h<0$, and so we take $t<0$ and find a similar result:
    \begin{align*}
        \varphi_{S_n}(t)=(\varphi_{X_1^{-1}}(t/n))^n=\bp{1+\varphi_{X_1^{-1}}^{-\prime}(0)\frac{t}{n}+o(t/n)}^n=\bp{1+\frac{\pi t+no(t/n)}{n}}^n\longrightarrow e^{\pi t}\quad\text{as $n\rightarrow\infty$}.\tag{10}
    \end{align*}
    Before stating the conclusion, we need to compute the limit when $t=0$:
    \begin{align*}
        \varphi_{S_n}(0)=(\varphi_{X_1^{-1}}(0/n))^n=1\tag{11}
    \end{align*}
    so, $\forall t\in\mbb{R}$, the limit of $\varphi_{S_n}(t)$ as $n\rightarrow\infty$ is summarized
    \begin{align*}
        \lim_{n\rightarrow\infty}\varphi_{S_n}(t)=e^{-\pi|t|}.
    \end{align*}
    This says that the law of $S_n$ converges weakly to the law of some random variable $\xi$ with characteristic function $\varphi_\xi(t)=e^{-\pi|t|}$. 
    The law of a Cauchy random variable is given by $e^{-|t|}$ [2], so we claim that $\xi$ is a Cauchy random variable with scale parameter $\pi$. Such a random variable has density
    \begin{align*}
        f_\xi(x)=\frac{1}{\pi}\frac{1}{\pi(1+(x/\pi)^2)}
    \end{align*} 
    so to verify the claim, we compute the characteristic function of $\xi$:
    \begin{align*}
        \varphi_\xi(t)=\int_\mbb{R}e^{itx}\frac{1}{\pi^2(1+(x/\pi)^2)}dx&=\frac{1}{\pi^2}\int_\mbb{R}e^{it\pi u}\frac{\pi}{1+u^2}du\tag{setting $u=x/\pi$}\\
        &=\int_\mbb{R}e^{it\pi u}\frac{1}{\pi}\frac{1}{1+u^2}du\tag{12}
    \end{align*}
    where $1/(\pi(1+u^2))$ is the density of a standard Cauchy random variable, (12) is the characteristic function of such a random variable evaluated at $t\pi$. That is, $\forall t\in\mbb{R}$,
    \begin{align*}
        \varphi_\xi(t)=e^{-|\pi t|}=e^{-\pi|t|}=\lim_{n\rightarrow\infty}\varphi_{S_n}(t)
    \end{align*}
    so finally, we have $\mc{L}(S_n)\Longrightarrow\mc{L}(\xi)$ as $n\rightarrow\infty$, a Cauchy random variable with scale parameter $\pi$.\hfill{$\qed$}\\[15pt]
    \begin{center}
        {\bf\large References}
    \end{center}
    \begin{enumerate}
        \item M. Abramowitz, I. Stegun, and D. Miller, {\it Handbook of mathematical functions with formulas, graphs and mathematical tables (National Bureau of Standards Applied Mathematics Series No. 55)}, J. Appl. Mech. (1965), \textbf{32}, 239-239.
        \item R. Dudley, {\it Real Analysis and Probability}, Cambridge Studies in Advanced Mathematics, Cambridge University Press, Cambridge, 2002.
        \item J. Richards and H. Youn, {\it The theory of distributions}, Cambridge University Press, Cambridge, 1990.
        \item Wolfram Research, Inc., Wolfram|Alpha, Champaign, IL (2024) URL: https://www.wolframalpha.com/calculators/integral-calculator/.
    \end{enumerate}
\end{document}
