\documentclass[10pt]{article}
\usepackage[margin=1.3cm]{geometry}

% Packages
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{bbm} 
\usepackage{dutchcal} % [dutchcal, calrsfs, pzzcal] calligraphic fonts
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[tracking]{microtype}

% Palatino for text goes well with Euler
\usepackage[sc,osf]{mathpazo}   % With old-style figures and real smallcaps.
\linespread{1.025}              % Palatino leads a little more leading

% Euler for math and numbers
\usepackage[euler-digits,small]{eulervm}

% Command initialization
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\graphicspath{{./images/}}

% Custom Commands
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\bp}[1]{\left({#1}\right)}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\1}[1]{\mathbbm{1}_{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\nck}[2]{{#1\choose#2}}
\newcommand{\pc}[1]{\pazocal{#1}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand*{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand*{\ceil}[1]{\left\lceil#1\right\rceil}

\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\sgm}{sgm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}
    \begin{center}
        {\bf\large{MATH 857: STATISTICAL LEARNING II}}
        \smallskip
        \hrule
        \smallskip
        {\bf Assignment 3} \hfill {\bf Connor Braun} \hfill {\bf 2024-03-03}
    \end{center}
    \noindent{\bf Problem 2}\\[5pt]
    {\bf a)}\hspace{5pt}Let $\phi:\mathbb{R}\rightarrow\mbb{R}$ be a differentiable function. Show that if the first-order
    derivative $\phi^\prime$ is non-decreasing, then for any $x,y\in\mbb{R}$, we have
    \[\phi(y)\geq \phi(x)+\phi^\prime(x)(y-x).\]
    {\bf Proof}\hspace{5pt} With $\phi$ as described, take some $x,y\in\mathbb{R}$ and without loss of generality let us have that $x<y$ (since if $x=y$ then the proof is trivial). 
    Then $\phi$ is differentiable on $[x,y]$, so by the mean value theorem $\exists c\in[x,y]$ satisfying
    \[\phi(y)-\phi(x)=\phi^\prime(c)(y-x)\quad\Rightarrow\quad \phi(y)=\phi(x)+\phi^\prime(c)(y-x)\]
    but $\phi^\prime$ is non-decreasing, so $x\leq c$ implies that $\phi^\prime(x)\leq \phi^\prime(c)$ and so from the above we obtain
    \[\phi(y)\geq \phi(x)+\phi^\prime(x)(y-x)\]
    which holds since $y-x>0$. Thus, any such $\phi$ is convex. \hfill{$\qed$}\\[5pt]
    {\bf b)}\hspace{5pt} Let $M>0$ be a fixed number and consider the following so-called Huber loss function: for $u\in\mbb{R}$,
    \begin{align*}
        \phi_M(u)&=\begin{cases}
            u^2\quad&\text{if $|u|\leq M$}\\
            2M|u|-M^2\quad&\text{if $|u|>M$}
        \end{cases}.
    \end{align*}
    Compute the derivative $\phi^\prime_M(u)$ for $u\in\mbb{R}$ and use part (a) to conclude that $\phi_M$ is a convex function.\\[5pt]
    {\bf Solution}\hspace{5pt} Fix $M>0$, and consider some $u,v,w\in\mbb{R}$ with $|u|<M$ and $v<-M$ and $w>M$. For these we have
    \begin{align*}
        &\phi_M^\prime(u)=2u\\
        &\phi_M(v)=-2Mv-M^2\quad\Rightarrow\quad \phi^\prime_M(v)=-2M\\
        &\phi_M(w)=2Mw-M^2\quad\Rightarrow\quad\phi^\prime_M(w)=2M
    \end{align*}
    from which we clearly see that $\lim_{x\rightarrow -M}\phi^\prime_M(x)=-2M$ and $\lim_{x\rightarrow M}\phi_M^\prime(x)=2M$. Thus, $\phi_M$ is differentiable on $\mbb{R}$ and 
    \[\phi_M^\prime(x)=\begin{cases}
        -2M\quad&\text{if $x<-M$}\\
        2x\quad&\text{if $|x|\leq M$}\\
        2M\quad&\text{if $x>M$}
    \end{cases}\]
    wherefrom it is also clear that $\phi^\prime_M$ is non-decreasing. Thus, by part (a), $\phi_M$ is convex.\\[5pt]
    {\bf Problem 3}\\[5pt]
    Consider a function $f:\mbb{R}\rightarrow\mbb{R}$ given by
    \[f(x)=(x-1)^6+(x-3)^4+(x-5)^2.\]
    Show that $f$ is convex.\\[5pt]
    {\bf Solution}\hspace{5pt} We can simply differentiate twice to find
    \begin{align*}
        f^\prime(x)=6(x-1)^5+4(x-3)^3+2(x-5),\qquad f^{\prime\prime}(x)=30(x-1)^4+12(x-3)^2+2>0\quad\forall x\in\mbb{R}
    \end{align*}
    so in fact $f$ is strictly convex on $\mbb{R}$.\hfill{$\qed$}\\[5pt]
    {\bf Problem 4}\\[5pt]
    Let $\sigma(z)=\log(1+e^{-z})$ for $x\in\mbb{R}$. By differentiating, show that it is a convex function. Further, show that for a fixed $\beta\in\mbb{R}^p$, the function
    $f(x)=\log(1+e^{-\beta^Tx})$ for $x\in\mbb{R}^p$ is convex.\\[5pt]
    {\bf Proof}\hspace{5pt} We proceed directly by first differentiating $\sigma$ to find
    \begin{align*}
        \sigma^\prime(z)=\frac{-e^{-z}}{1+e^{-z}},\qquad \sigma^{\prime\prime}(z)=\frac{e^{-z}(1+e^{-z})+e^{-z}(-e^{-z})}{(1+e^{-z})^2}=\frac{e^{-z}+e^{-2z}-e^{-2z}}{(1+e^{-z})^2}=\frac{e^{-z}}{(1+e^{-z})^2}>0\quad\forall z\in\mbb{R}
    \end{align*}
    so indeed, $\sigma$ is strictly convex on $\mbb{R}$. Next, let $\alpha\in[0,1]$ and $x,y\in\mbb{R}^p$. Then, setting $z_1=\beta^Tx$ and $z_2=\beta^Ty$ we get
    \begin{align*}
        f(\alpha x+(1-\alpha y))=\log\bp{1+e^{-\beta^T(\alpha x+(1-\alpha)y)}}&=\log\bp{1+e^{-(\alpha z_1+(1-\alpha)z_2)}}\\
        &=\sigma(\alpha z_1+(1-\alpha)z_2)\\
        &<\alpha\sigma(z_1)+(1-\alpha)\sigma(z_2)\tag{since $\sigma$ strictly convex}\\
        &=\alpha\log\bp{1+e^{-\beta^Tx}}+(1-\alpha)\log\bp{1+e^{-\beta^Ty}}\\
        &=\alpha f(x)+(1-\alpha)f(y)
    \end{align*}
    which says that $f$ is also strictly convex on $\mbb{R}^p$.\hfill{$\qed$}
\end{document}